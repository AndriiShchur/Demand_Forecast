{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import calendar\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "items = pd.read_csv(r'Data\\items.csv')\n",
    "shops = pd.read_csv(r'Data\\shops.csv')\n",
    "cats = pd.read_csv(r'Data\\item_categories.csv')\n",
    "train = pd.read_csv(r'Data\\sales_train.csv')\n",
    "\n",
    "# set index to ID to avoid droping it later\n",
    "test  = pd.read_csv(r'Data\\test.csv').set_index('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace minus price by median\n",
    "\n",
    "median = train[(train.shop_id==32)&(train.item_id==2973)&(train.date_block_num==4)&(train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price<0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several shops are duplicates of each other (according to its name). Fix train and test set.\n",
    "\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shops/Cats/Items preprocessing\n",
    "Observations:\n",
    "\n",
    "- Each shop_name starts with the city name.\n",
    "- Each category contains type and subtype in its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "shops['shop_category'] = 'NA'\n",
    "\n",
    "for index, row in tqdm(shops.iterrows()):\n",
    "    shops['shop_category'].iloc[index]\n",
    "\n",
    "    if 'ТЦ' in shops['shop_name'].iloc[index]:\n",
    "        shops['shop_category'].iloc[index] = '1'\n",
    "    elif  'ТРЦ' in shops['shop_name'].iloc[index] or 'ТРК' in shops['shop_name'].iloc[index]:\n",
    "        shops['shop_category'].iloc[index] = '2'\n",
    "    else:\n",
    "        shops['shop_category'].iloc[index] = '3'\n",
    "\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = shops[['shop_id','city_code','shop_category']]\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "# if subtype is nan then type\n",
    "cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code', 'subtype_code']]\n",
    "cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(['item_name'], axis=1, inplace=True)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly sales\n",
    "Test set is a product of some shops and some items within 34 month. There are 5100 items * 42 shops = 214200 pairs. 363 items are new compared to the train. Hence, for the most of the items in the test set target value should be zero. In the other hand train set contains only pairs which were sold or returned in the past. Tha main idea is to calculate monthly sales and extend it with zero sales for each unique pair within the month. This way train data will be similar to test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info\n",
    "len(list(set(test.item_id) - set(test.item_id).intersection(set(train.item_id)))), len(list(set(test.item_id))), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe with all unique pairs\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "    \n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix['item_id'] = matrix['item_id'].astype(np.int16)\n",
    "matrix.sort_values(cols,inplace=True)\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge empty dataframe with history Sales\n",
    "\n",
    "train['revenue'] = train['item_price'] *  train['item_cnt_day']\n",
    "group = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=cols, how='left')\n",
    "matrix['item_cnt_month'] = (matrix['item_cnt_month']\n",
    "                                .fillna(0)\n",
    "                                .clip(0,20) # NB clip target here\n",
    "                                .astype(np.float16))\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add test dataframe\n",
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)\n",
    "\n",
    "matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\n",
    "matrix.fillna(0, inplace=True) # 34 month\n",
    "\n",
    "matrix.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join and encode category features\n",
    "Shops/Items/category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\n",
    "matrix = pd.merge(matrix, items, on=['item_id'], how='left')\n",
    "matrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\n",
    "matrix['city_code'] = matrix['city_code'].astype(np.int8)\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['type_code'] = matrix['type_code'].astype(np.int8)\n",
    "matrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for category features encoding\n",
    "\n",
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fuatures for Item\n",
    "matrix = lag_feature(matrix, [1,2,3,4,5,6,12], 'item_cnt_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\n",
    "matrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_avg_item_cnt')\n",
    "matrix.drop(['date_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_item_avg_item_cnt')\n",
    "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_shop_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n",
    "matrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_cat_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\n",
    "matrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\n",
    "matrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_cat_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\n",
    "matrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_type_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\n",
    "matrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\n",
    "matrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
    "matrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\n",
    "matrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\n",
    "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\n",
    "matrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\n",
    "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_type_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\n",
    "matrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\n",
    "matrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_subtype_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\n",
    "matrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_id', 'shop_category']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_shop_category_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_category'], how='left')\n",
    "matrix['date_item_shop_category_avg_item_cnt'] = matrix['date_item_shop_category_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_item_shop_category_avg_item_cnt')\n",
    "matrix.drop(['date_item_shop_category_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shops coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops = pd.read_csv(r'C:\\Users\\anshch\\Documents\\Demand_Forecast\\Data\\shops.csv')\n",
    "\n",
    "shops['city'] = shops['shop_name'].apply(lambda x: x.split()[0].lower())\n",
    "shops.loc[shops.city == '!якутск', 'city'] = 'якутск'\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city'])\n",
    "\n",
    "coords = dict()\n",
    "coords['якутск'] = (62.028098, 129.732555, 4)\n",
    "coords['адыгея'] = (44.609764, 40.100516, 3)\n",
    "coords['балашиха'] = (55.8094500, 37.9580600, 1)\n",
    "coords['волжский'] = (53.4305800, 50.1190000, 3)\n",
    "coords['вологда'] = (59.2239000, 39.8839800, 2)\n",
    "coords['воронеж'] = (51.6720400, 39.1843000, 3)\n",
    "coords['выездная'] = (0, 0, 0)\n",
    "coords['жуковский'] = (55.5952800, 38.1202800, 1)\n",
    "coords['интернет-магазин'] = (0, 0, 0)\n",
    "coords['казань'] = (55.7887400, 49.1221400, 4)\n",
    "coords['калуга'] = (54.5293000, 36.2754200, 4)\n",
    "coords['коломна'] = (55.0794400, 38.7783300, 4)\n",
    "coords['красноярск'] = (56.0183900, 92.8671700, 4)\n",
    "coords['курск'] = (51.7373300, 36.1873500, 3)\n",
    "coords['москва'] = (55.7522200, 37.6155600, 1)\n",
    "coords['мытищи'] = (55.9116300, 37.7307600, 1)\n",
    "coords['н.новгород'] = (56.3286700, 44.0020500, 4)\n",
    "coords['новосибирск'] = (55.0415000, 82.9346000, 4)\n",
    "coords['омск'] = (54.9924400, 73.3685900, 4)\n",
    "coords['ростовнадону'] = (47.2313500, 39.7232800, 3)\n",
    "coords['спб'] = (59.9386300, 30.3141300, 2)\n",
    "coords['самара'] = (53.2000700, 50.1500000, 4)\n",
    "coords['сергиев'] = (56.3000000, 38.1333300, 4)\n",
    "coords['сургут'] = (61.2500000, 73.4166700, 4)\n",
    "coords['томск'] = (56.4977100, 84.9743700, 4)\n",
    "coords['тюмень'] = (57.1522200, 65.5272200, 4)\n",
    "coords['уфа'] = (54.7430600, 55.9677900, 4)\n",
    "coords['химки'] = (55.8970400, 37.4296900, 1)\n",
    "coords['цифровой'] = (0, 0, 0)\n",
    "coords['чехов'] = (55.1477000, 37.4772800, 4)\n",
    "coords['ярославль'] = (57.6298700, 39.8736800, 2) \n",
    "\n",
    "shops['city_coord_1'] = shops['city'].apply(lambda x: coords[x][0])\n",
    "shops['city_coord_2'] = shops['city'].apply(lambda x: coords[x][1])\n",
    "shops['country_part'] = shops['city'].apply(lambda x: coords[x][2])\n",
    "\n",
    "shops = shops[['shop_id', 'city_coord_1', 'city_coord_2', 'country_part']]\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend features\n",
    "Price trend for the last N months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['item_id'], how='left')\n",
    "matrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "group = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['date_item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n",
    "\n",
    "lags = [1,2,3,4,5,6]\n",
    "matrix = lag_feature(matrix, lags, 'date_item_avg_item_price')\n",
    "\n",
    "for i in lags:\n",
    "    matrix['delta_price_lag_'+str(i)] = \\\n",
    "        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n",
    "\n",
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0\n",
    "    \n",
    "matrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\n",
    "matrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\n",
    "matrix['delta_price_lag'].fillna(0, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe from unuse columns\n",
    "\n",
    "fetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "matrix.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last month shop revenue trend\n",
    "\n",
    "group = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\n",
    "group.columns = ['date_shop_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n",
    "\n",
    "group = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\n",
    "group.columns = ['shop_avg_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['shop_id'], how='left')\n",
    "matrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n",
    "\n",
    "matrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
    "matrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'delta_revenue')\n",
    "\n",
    "matrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['month'] = matrix['date_block_num'] % 12\n",
    "\n",
    "# Number of days in a month. There are no leap years.\n",
    "\n",
    "days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "matrix['days'] = matrix['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Months since the last sale for each shop/item pair and for item only. I use programing approach.\n",
    "\n",
    "Create HashTable with key equals to {shop_id,item_id} and value equals to date_block_num. Iterate data from the top. Foreach row if {row.shop_id,row.item_id} is not present in the table, then add it to the table and set its value to row.date_block_num. if HashTable contains key, then calculate the difference beteween cached value and row.date_block_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "matrix['item_shop_last_sale'] = -1\n",
    "matrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        cache[key] = row.date_block_num \n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "matrix['item_last_sale'] = -1\n",
    "matrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num>last_date_block_num:\n",
    "            matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "            cache[key] = row.date_block_num\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months since the first sale for each shop/item pair and for item only.\n",
    "matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "matrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the using 12 as lag value drop first 12 months. Also drop all the columns with this month calculated values (other words which can not be calcucated for the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "matrix = matrix[matrix.date_block_num > 11]\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_days(date_block_num):\n",
    "    year = 2013 + date_block_num // 12\n",
    "    month = 1 + date_block_num % 12\n",
    "    weeknd_count = len([1 for i in calendar.monthcalendar(year, month) if i[6] != 0])\n",
    "    days_in_month = calendar.monthrange(year, month)[1]\n",
    "    return weeknd_count, days_in_month, month\n",
    "\n",
    "map_dict = {i: count_days(i) for i in range(35)}\n",
    "\n",
    "matrix['weeknd_count'] = matrix['date_block_num'].apply(lambda x: map_dict[x][0])\n",
    "matrix['days_in_month'] = matrix['date_block_num'].apply(lambda x: map_dict[x][1])\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA value\n",
    "\n",
    "def fill_na(df):\n",
    "    for col in df.columns:\n",
    "        if ('_lag_' in col) & (df[col].isnull().any()):\n",
    "            if ('item_cnt' in col):\n",
    "                df[col].fillna(0, inplace=True)         \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = fill_na(matrix)\n",
    "\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.to_pickle(r'Data\\data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_pickle(r'Data\\test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}