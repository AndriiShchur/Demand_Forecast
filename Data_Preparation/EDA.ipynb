{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('kaggle38': conda)",
   "metadata": {
    "interpreter": {
     "hash": "45e47e45928c796b447ddcb91a7dea648bf57b34fd0dbb45cb997aadc6b2e9c6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import nltk, datetime\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "items = pd.read_csv(r'Data\\items.csv')\n",
    "shops = pd.read_csv(r'Data\\shops.csv')\n",
    "item_cats  = pd.read_csv(r'Data\\item_categories.csv')\n",
    "train = pd.read_csv(r'Data\\sales_train.csv')\n",
    "test  = pd.read_csv(r'Data\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "source": [
    "# Data Understanding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining datasets\n",
    "train_full = pd.merge(train, items, how='left', on=['item_id','item_id'])\n",
    "train_full = pd.merge(train_full, item_cats, how='left', on=['item_category_id','item_category_id'])\n",
    "train_full = pd.merge(train_full, shops, how='left', on=['shop_id','shop_id'])\n",
    "\n",
    "# Adding date features\n",
    "train_full['date'] = pd.to_datetime(train_full['date'], format='%d.%m.%Y')\n",
    "train_full['month'] = train_full['date'].dt.month\n",
    "train_full['year'] = train_full['date'].dt.year\n",
    "\n",
    "# Selecting feature set\n",
    "col = ['date_block_num', 'date', 'month', 'year', 'shop_id', 'item_category_id', 'item_id', 'item_price',\n",
    "       'item_cnt_day', 'shop_name', 'item_category_name','item_name',\n",
    "      ]\n",
    "train_full = train_full[col]\n",
    "train_full['revenue'] = train_full.item_price * train_full.item_cnt_day\n",
    "\n",
    "print(\"Description of training set\")\n",
    "print(\"Shape: \\t\\t\\t\", train_full.shape)\n",
    "print(\"#NaNs: \\t\\t\\t\", train_full.isna().sum().sum()) # No NaN\n",
    "print(\"#Shops: \\t\\t\", train_full.shop_id.nunique())\n",
    "print(\"#Item Categories: \\t\", train_full.item_category_id.nunique())\n",
    "print(\"#Items: \\t\\t\", train_full.item_id.nunique())\n",
    "print(\"#Months: \\t\\t\", train_full.date_block_num.nunique())\n",
    "print(\"Date range from: \\t\", train_full.date.min(), \" to \", train_full.date.max())\n",
    "print(\"Price range from: \\t\", train_full.item_price.min(), \" to \", train_full.item_price.max())\n",
    "print(\"Units Sold range from: \\t\", train_full.item_cnt_day.min(), \" to \", train_full.item_cnt_day.max())\n",
    "print(\"Revenue range from: \\t\", train_full.revenue.min(), \" to \", train_full.revenue.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average item price\n",
    "item_price = train_full[['item_id', 'item_price']].groupby('item_id')['item_price'].mean()\n",
    "\n",
    "item_price = item_price.reset_index()\n",
    "item_price = item_price.rename(columns={'item_price':'avg_item_price'})\n",
    "\n",
    "train_agg = train_full[['date_block_num', 'month', 'year', 'shop_id', 'item_category_id', 'item_id', 'item_cnt_day', 'revenue']].groupby(\n",
    "    ['date_block_num', 'shop_id', 'item_category_id', 'item_id'])[\n",
    "    ['item_cnt_day', 'revenue']].sum()\n",
    "\n",
    "train_agg = train_agg.reset_index()\n",
    "train_agg = train_agg.rename(columns={'item_cnt_day':'units_sold'})\n",
    "\n",
    "print(\"Shape of complete training set:\", train_agg.shape)\n",
    "\n",
    "train_agg = train_agg[train_agg.units_sold >= 0.0] # Subsetting for sales between 0 to 20 units per month\n",
    "train_agg = train_agg[train_agg.units_sold <= 20.0]\n",
    "print(\"Shape of selected training set:\", train_agg.shape)\n",
    "\n",
    "# Add average price\n",
    "train_agg = pd.merge(train_agg, item_price, how='left', left_on='item_id', right_on='item_id')\n",
    "\n",
    "train_agg[['units_sold', 'avg_item_price', 'revenue']].describe(percentiles=[.01, .5, .95, .99]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scater p;ot\n",
    "df = train_agg[['item_category_id', 'units_sold', 'revenue']].groupby(\n",
    "    ['item_category_id'])['units_sold', 'revenue'].sum()\n",
    "\n",
    "df = df.reset_index()\n",
    "df['avg_item_price'] = round(df.revenue / df.units_sold, 2)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 4))\n",
    "plt.scatter(y=\"units_sold\", x=\"avg_item_price\", data=df, c=\"b\", s=30, linewidth=1, marker=\"+\")\n",
    "plt.xlabel(\"AVG Item price\")\n",
    "plt.ylabel(\"Units sold\")\n",
    "plt.title(\"For each item category \\nUnits Sold ~ Avg item price\");"
   ]
  },
  {
   "source": [
    "# Plotting Overall Monthly trend"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_agg[['date_block_num', 'item_id']].groupby(by='date_block_num', as_index=False).nunique()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "plt.plot(df.item_id, sns.xkcd_rgb[\"denim blue\"], lw=4)\n",
    "plt.title(\"Count of Unique items sold\")\n",
    "\n",
    "\n",
    "df = train_agg[['date_block_num', 'units_sold']].groupby(by='date_block_num', as_index=False).sum()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 4))\n",
    "plt.plot(df.units_sold, sns.xkcd_rgb[\"denim blue\"], lw=4)\n",
    "plt.title(\"Sum of items sold\")\n",
    "\n",
    "\n",
    "df = train_agg[['date_block_num', 'revenue']].groupby(by='date_block_num', as_index=False).sum()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 4))\n",
    "plt.plot(df.revenue, sns.xkcd_rgb[\"denim blue\"], lw=4)\n",
    "plt.title(\"Total revenue generated\");"
   ]
  },
  {
   "source": [
    "# Shop analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_hm = train_agg.pivot_table(index='date_block_num', columns='shop_id', values='item_id', aggfunc='nunique', fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "cmap = sns.cubehelix_palette(8, as_cmap=True, dark=0, light=1, gamma=0.8, reverse=True)\n",
    "plt.title(\"Count of Unique items sold\")\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cmap=cmap, cbar=False, xticklabels=False)\n",
    "\n",
    "\n",
    "stores_hm = train_agg.pivot_table(index='date_block_num', columns='shop_id', values='units_sold', aggfunc='sum', fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "cmap = sns.cubehelix_palette(8, as_cmap=True, dark=0, light=1, gamma = .8, reverse=True)\n",
    "plt.title(\"Sum of items sold\")\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cmap=cmap, cbar=False, xticklabels=False)\n",
    "\n",
    "\n",
    "stores_hm = train_agg.pivot_table(index='date_block_num', columns='shop_id', values='revenue', aggfunc='sum', fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "cmap = sns.cubehelix_palette(8, as_cmap=True, dark=0, light=1, gamma = .8, reverse=True)\n",
    "plt.title(\"Total revenue generated\")\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cmap=cmap, cbar=False, xticklabels=False)"
   ]
  },
  {
   "source": [
    "# Category analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_hm = train_agg.pivot_table(index='date_block_num', columns='item_category_id', values='item_id', aggfunc='nunique', fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "cmap = sns.cubehelix_palette(8, as_cmap=True, dark=0, light=1, gamma=0.8, reverse=True)\n",
    "plt.title(\"Count of Unique items sold\")\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cmap=cmap, cbar=False, xticklabels=False)\n",
    "\n",
    "\n",
    "stores_hm = train_agg.pivot_table(index='date_block_num', columns='item_category_id', values='units_sold', aggfunc='sum', fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "cmap = sns.cubehelix_palette(8, as_cmap=True, dark=0, light=1, gamma = .8, reverse=True)\n",
    "plt.title(\"Sum of items sold\")\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cmap=cmap, cbar=False, xticklabels=False)\n",
    "\n",
    "\n",
    "stores_hm = train_agg.pivot_table(index='date_block_num', columns='item_category_id', values='revenue', aggfunc='sum', fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "cmap = sns.cubehelix_palette(8, as_cmap=True, dark=0, light=1, gamma = .8, reverse=True)\n",
    "plt.title(\"Total revenue generated\")\n",
    "_ = sns.heatmap(stores_hm, ax=ax, cmap=cmap, cbar=False, xticklabels=False)"
   ]
  },
  {
   "source": [
    "# What category/shop sells more?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(items, on='item_id', rsuffix='_').join(shops, on='shop_id', rsuffix='_').join(item_cats, on='item_category_id', rsuffix='_').drop(['item_id_', 'shop_id_', 'item_category_id_'], axis=1)\n",
    "\n",
    "test_shop_ids = test['shop_id'].unique()\n",
    "test_item_ids = test['item_id'].unique()\n",
    "# Only shops that exist in test set.\n",
    "train = train[train['shop_id'].isin(test_shop_ids)]\n",
    "# Only items that exist in test set.\n",
    "train = train[train['item_id'].isin(test_item_ids)]\n",
    "train = train.query('item_price > 0')\n",
    "\n",
    "train_monthly = train[['date', 'date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'item_cnt_day']]\n",
    "\n",
    "# Group by month in this case \"date_block_num\" and aggregate features.\n",
    "train_monthly = train_monthly.sort_values('date').groupby(['date_block_num', 'shop_id', 'item_category_id', 'item_id'], as_index=False)\n",
    "train_monthly = train_monthly.agg({'item_price':['sum', 'mean'], 'item_cnt_day':['sum', 'mean','count']})\n",
    "# Rename features.\n",
    "train_monthly.columns = ['date_block_num', 'shop_id', 'item_category_id', 'item_id', 'item_price', 'mean_item_price', 'item_cnt', 'mean_item_cnt', 'transactions']\n",
    "\n",
    "# Build a data set with all the possible combinations of ['date_block_num','shop_id','item_id'] so we won't have missing records.\n",
    "shop_ids = train_monthly['shop_id'].unique()\n",
    "item_ids = train_monthly['item_id'].unique()\n",
    "empty_df = []\n",
    "for i in range(34):\n",
    "    for shop in shop_ids:\n",
    "        for item in item_ids:\n",
    "            empty_df.append([i, shop, item])\n",
    "    \n",
    "empty_df = pd.DataFrame(empty_df, columns=['date_block_num','shop_id','item_id'])\n",
    "\n",
    "# Merge the train set with the complete set (missing records will be filled with 0).\n",
    "train_monthly = pd.merge(empty_df, train_monthly, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "train_monthly.fillna(0, inplace=True)\n",
    "\n",
    "# Extract time based features.\n",
    "train_monthly['year'] = train_monthly['date_block_num'].apply(lambda x: ((x//12) + 2013))\n",
    "train_monthly['month'] = train_monthly['date_block_num'].apply(lambda x: (x % 12))\n",
    "\n",
    "gp_category_mean = train_monthly.groupby(['item_category_id'], as_index=False)['item_cnt'].mean()\n",
    "gp_category_sum = train_monthly.groupby(['item_category_id'], as_index=False)['item_cnt'].sum()\n",
    "gp_shop_mean = train_monthly.groupby(['shop_id'], as_index=False)['item_cnt'].mean()\n",
    "gp_shop_sum = train_monthly.groupby(['shop_id'], as_index=False)['item_cnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 1, figsize=(22, 10), sharex=True)\n",
    "sns.barplot(x=\"item_category_id\", y=\"item_cnt\", data=gp_category_mean, ax=axes[0], palette=\"rocket\").set_title(\"Monthly mean\")\n",
    "sns.barplot(x=\"item_category_id\", y=\"item_cnt\", data=gp_category_sum, ax=axes[1], palette=\"rocket\").set_title(\"Monthly sum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 1, figsize=(22, 10), sharex=True)\n",
    "sns.barplot(x=\"shop_id\", y=\"item_cnt\", data=gp_shop_mean, ax=axes[0], palette=\"rocket\").set_title(\"Monthly mean\")\n",
    "sns.barplot(x=\"shop_id\", y=\"item_cnt\", data=gp_shop_sum, ax=axes[1], palette=\"rocket\").set_title(\"Monthly sum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}